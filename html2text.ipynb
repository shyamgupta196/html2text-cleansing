{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **HTML Information Extraction Toolkit**\n",
    "#### Introduction\n",
    "\n",
    "This notebook demonstrates how to preprocess HTML pages and extract useful textual information. It uses two Python libraries: \n",
    "- `trafilatura` for general-purpose text extraction.\n",
    "- `news-please` for structured information extraction, especially for news articles.\n",
    "\n",
    "We will walk through the process step-by-step, extracting clean and meaningful text from raw HTML files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Required Libraries**\n",
    "Make sure you have the necessary libraries installed. If not, run the following command in your terminal or notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: trafilatura in /usr/local/python/3.12.1/lib/python3.12/site-packages (2.0.0)\n",
      "Requirement already satisfied: news-please in /usr/local/python/3.12.1/lib/python3.12/site-packages (1.6.15)\n",
      "Requirement already satisfied: certifi in /home/codespace/.local/lib/python3.12/site-packages (from trafilatura) (2025.7.9)\n",
      "Requirement already satisfied: charset_normalizer>=3.4.0 in /home/codespace/.local/lib/python3.12/site-packages (from trafilatura) (3.4.2)\n",
      "Requirement already satisfied: courlan>=1.3.2 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from trafilatura) (1.3.2)\n",
      "Requirement already satisfied: htmldate>=1.9.2 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from trafilatura) (1.9.3)\n",
      "Requirement already satisfied: justext>=3.0.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from trafilatura) (3.0.2)\n",
      "Requirement already satisfied: lxml>=5.3.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from trafilatura) (5.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in /home/codespace/.local/lib/python3.12/site-packages (from trafilatura) (2.5.0)\n",
      "Requirement already satisfied: Scrapy>=1.1.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from news-please) (2.13.3)\n",
      "Requirement already satisfied: PyMySQL>=0.7.9 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from news-please) (1.1.1)\n",
      "Requirement already satisfied: psycopg2-binary>=2.8.4 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from news-please) (2.9.10)\n",
      "Requirement already satisfied: hjson>=1.5.8 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from news-please) (3.1.0)\n",
      "Requirement already satisfied: elasticsearch>=2.4 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from news-please) (9.1.0)\n",
      "Requirement already satisfied: beautifulsoup4>=4.3.2 in /home/codespace/.local/lib/python3.12/site-packages (from news-please) (4.13.4)\n",
      "Requirement already satisfied: readability-lxml>=0.6.2 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from news-please) (0.8.4.1)\n",
      "Requirement already satisfied: langdetect>=1.0.7 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from news-please) (1.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.4.0 in /home/codespace/.local/lib/python3.12/site-packages (from news-please) (2.9.0.post0)\n",
      "Requirement already satisfied: plac>=0.9.6 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from news-please) (1.4.5)\n",
      "Requirement already satisfied: dotmap>=1.2.17 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from news-please) (1.3.30)\n",
      "Requirement already satisfied: PyDispatcher>=2.0.5 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from news-please) (2.0.7)\n",
      "Requirement already satisfied: warcio>=1.3.3 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from news-please) (1.7.5)\n",
      "Requirement already satisfied: ago>=0.0.9 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from news-please) (0.1.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/codespace/.local/lib/python3.12/site-packages (from news-please) (1.17.0)\n",
      "Requirement already satisfied: hurry.filesize>=0.9 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from news-please) (0.9)\n",
      "Requirement already satisfied: bs4 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from news-please) (0.0.2)\n",
      "Requirement already satisfied: faust-cchardet>=2.1.18 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from news-please) (2.1.19)\n",
      "Requirement already satisfied: boto3 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from news-please) (1.40.1)\n",
      "Requirement already satisfied: redis in /usr/local/python/3.12.1/lib/python3.12/site-packages (from news-please) (6.2.0)\n",
      "Requirement already satisfied: newspaper4k>=0.9.3.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from news-please) (0.9.3.1)\n",
      "Requirement already satisfied: lxml-html-clean>=0.1.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from news-please) (0.4.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7.0 in /home/codespace/.local/lib/python3.12/site-packages (from news-please) (4.14.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/codespace/.local/lib/python3.12/site-packages (from beautifulsoup4>=4.3.2->news-please) (2.7)\n",
      "Requirement already satisfied: babel>=2.16.0 in /home/codespace/.local/lib/python3.12/site-packages (from courlan>=1.3.2->trafilatura) (2.17.0)\n",
      "Requirement already satisfied: tld>=0.13 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from courlan>=1.3.2->trafilatura) (0.13.1)\n",
      "Requirement already satisfied: elastic-transport<10,>=9.1.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from elasticsearch>=2.4->news-please) (9.1.0)\n",
      "Requirement already satisfied: dateparser>=1.1.2 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from htmldate>=1.9.2->trafilatura) (1.2.2)\n",
      "Requirement already satisfied: pytz>=2024.2 in /home/codespace/.local/lib/python3.12/site-packages (from dateparser>=1.1.2->htmldate>=1.9.2->trafilatura) (2025.2)\n",
      "Requirement already satisfied: regex>=2024.9.11 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from dateparser>=1.1.2->htmldate>=1.9.2->trafilatura) (2025.7.34)\n",
      "Requirement already satisfied: tzlocal>=0.2 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from dateparser>=1.1.2->htmldate>=1.9.2->trafilatura) (5.3.1)\n",
      "Requirement already satisfied: setuptools in /home/codespace/.local/lib/python3.12/site-packages (from hurry.filesize>=0.9->news-please) (80.9.0)\n",
      "Requirement already satisfied: Pillow>=4.0.0 in /home/codespace/.local/lib/python3.12/site-packages (from newspaper4k>=0.9.3.1->news-please) (11.3.0)\n",
      "Requirement already satisfied: PyYAML>=5.1 in /home/codespace/.local/lib/python3.12/site-packages (from newspaper4k>=0.9.3.1->news-please) (6.0.2)\n",
      "Requirement already satisfied: feedparser>=6.0.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from newspaper4k>=0.9.3.1->news-please) (6.0.11)\n",
      "Requirement already satisfied: nltk>=3.6.6 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from newspaper4k>=0.9.3.1->news-please) (3.9.1)\n",
      "Requirement already satisfied: numpy>=1.25 in /home/codespace/.local/lib/python3.12/site-packages (from newspaper4k>=0.9.3.1->news-please) (2.3.1)\n",
      "Requirement already satisfied: pandas>=2.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from newspaper4k>=0.9.3.1->news-please) (2.3.1)\n",
      "Requirement already satisfied: requests>=2.26.0 in /home/codespace/.local/lib/python3.12/site-packages (from newspaper4k>=0.9.3.1->news-please) (2.32.4)\n",
      "Requirement already satisfied: tldextract>=2.0.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from newspaper4k>=0.9.3.1->news-please) (5.3.0)\n",
      "Requirement already satisfied: sgmllib3k in /usr/local/python/3.12.1/lib/python3.12/site-packages (from feedparser>=6.0.0->newspaper4k>=0.9.3.1->news-please) (1.0.0)\n",
      "Requirement already satisfied: click in /usr/local/python/3.12.1/lib/python3.12/site-packages (from nltk>=3.6.6->newspaper4k>=0.9.3.1->news-please) (8.2.1)\n",
      "Requirement already satisfied: joblib in /home/codespace/.local/lib/python3.12/site-packages (from nltk>=3.6.6->newspaper4k>=0.9.3.1->news-please) (1.5.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/python/3.12.1/lib/python3.12/site-packages (from nltk>=3.6.6->newspaper4k>=0.9.3.1->news-please) (4.67.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/codespace/.local/lib/python3.12/site-packages (from pandas>=2.1.0->newspaper4k>=0.9.3.1->news-please) (2025.2)\n",
      "Requirement already satisfied: chardet in /usr/local/python/3.12.1/lib/python3.12/site-packages (from readability-lxml>=0.6.2->news-please) (5.2.0)\n",
      "Requirement already satisfied: cssselect in /usr/local/python/3.12.1/lib/python3.12/site-packages (from readability-lxml>=0.6.2->news-please) (1.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests>=2.26.0->newspaper4k>=0.9.3.1->news-please) (3.10)\n",
      "Requirement already satisfied: cryptography>=37.0.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from Scrapy>=1.1.0->news-please) (45.0.5)\n",
      "Requirement already satisfied: defusedxml>=0.7.1 in /home/codespace/.local/lib/python3.12/site-packages (from Scrapy>=1.1.0->news-please) (0.7.1)\n",
      "Requirement already satisfied: itemadapter>=0.1.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from Scrapy>=1.1.0->news-please) (0.12.0)\n",
      "Requirement already satisfied: itemloaders>=1.0.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from Scrapy>=1.1.0->news-please) (1.3.2)\n",
      "Requirement already satisfied: packaging in /home/codespace/.local/lib/python3.12/site-packages (from Scrapy>=1.1.0->news-please) (25.0)\n",
      "Requirement already satisfied: parsel>=1.5.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from Scrapy>=1.1.0->news-please) (1.10.0)\n",
      "Requirement already satisfied: protego>=0.1.15 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from Scrapy>=1.1.0->news-please) (0.5.0)\n",
      "Requirement already satisfied: pyopenssl>=22.0.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from Scrapy>=1.1.0->news-please) (25.1.0)\n",
      "Requirement already satisfied: queuelib>=1.4.2 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from Scrapy>=1.1.0->news-please) (1.8.0)\n",
      "Requirement already satisfied: service-identity>=18.1.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from Scrapy>=1.1.0->news-please) (24.2.0)\n",
      "Requirement already satisfied: twisted>=21.7.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from Scrapy>=1.1.0->news-please) (25.5.0)\n",
      "Requirement already satisfied: w3lib>=1.17.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from Scrapy>=1.1.0->news-please) (2.3.1)\n",
      "Requirement already satisfied: zope-interface>=5.1.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from Scrapy>=1.1.0->news-please) (7.2)\n",
      "Requirement already satisfied: cffi>=1.14 in /home/codespace/.local/lib/python3.12/site-packages (from cryptography>=37.0.0->Scrapy>=1.1.0->news-please) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /home/codespace/.local/lib/python3.12/site-packages (from cffi>=1.14->cryptography>=37.0.0->Scrapy>=1.1.0->news-please) (2.22)\n",
      "Requirement already satisfied: jmespath>=0.9.5 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from itemloaders>=1.0.1->Scrapy>=1.1.0->news-please) (1.0.1)\n",
      "Requirement already satisfied: attrs>=19.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from service-identity>=18.1.0->Scrapy>=1.1.0->news-please) (25.3.0)\n",
      "Requirement already satisfied: pyasn1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from service-identity>=18.1.0->Scrapy>=1.1.0->news-please) (0.6.1)\n",
      "Requirement already satisfied: pyasn1-modules in /usr/local/python/3.12.1/lib/python3.12/site-packages (from service-identity>=18.1.0->Scrapy>=1.1.0->news-please) (0.4.2)\n",
      "Requirement already satisfied: requests-file>=1.4 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from tldextract>=2.0.1->newspaper4k>=0.9.3.1->news-please) (2.1.0)\n",
      "Requirement already satisfied: filelock>=3.0.8 in /home/codespace/.local/lib/python3.12/site-packages (from tldextract>=2.0.1->newspaper4k>=0.9.3.1->news-please) (3.13.1)\n",
      "Requirement already satisfied: automat>=24.8.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from twisted>=21.7.0->Scrapy>=1.1.0->news-please) (25.4.16)\n",
      "Requirement already satisfied: constantly>=15.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from twisted>=21.7.0->Scrapy>=1.1.0->news-please) (23.10.4)\n",
      "Requirement already satisfied: hyperlink>=17.1.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from twisted>=21.7.0->Scrapy>=1.1.0->news-please) (21.0.0)\n",
      "Requirement already satisfied: incremental>=24.7.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from twisted>=21.7.0->Scrapy>=1.1.0->news-please) (24.7.2)\n",
      "Requirement already satisfied: botocore<1.41.0,>=1.40.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from boto3->news-please) (1.40.1)\n",
      "Requirement already satisfied: s3transfer<0.14.0,>=0.13.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from boto3->news-please) (0.13.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install trafilatura news-please\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 1: Import Necessary Libraries**\n",
    "\n",
    "Here, we import the required libraries to handle file operations, multiprocessing for efficiency, and text extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import multiprocessing\n",
    "import re\n",
    "import trafilatura\n",
    "from newsplease import NewsPlease"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 2: Set the Directory Path**\n",
    "\n",
    "\n",
    "Define the base directory where all your HTML files are stored. Make sure you have a folder named `html` containing the files you want to process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URI = 'html/'  # Update this path if your folder is elsewhere"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 3: Create a Function to Clean Text**\n",
    "\n",
    "\n",
    "The `clean_text` function removes unnecessary whitespace, redundant hyphens, and formatting inconsistencies to produce clean text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Cleans the extracted text by removing extra whitespace, unnecessary hyphens, etc.\n",
    "    \"\"\"\n",
    "    cleaned_text = re.sub(r\"\\s+\", \" \", text)  # Replace multiple spaces with a single space\n",
    "    cleaned_text = cleaned_text.strip()       # Strip leading and trailing whitespace\n",
    "    cleaned_text = cleaned_text.replace(\"- \", \"\")  # Remove hyphens followed by spaces\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 4: Create a Function to Extract Text Using Trafilatura**\n",
    "\n",
    "\n",
    "The `extract_text_trafilatura` function processes an HTML file to extract its main content and metadata using Trafilatura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_trafilatura(filename):\n",
    "    \"\"\"\n",
    "    Extracts text and metadata from an HTML file using Trafilatura.\n",
    "    \"\"\"\n",
    "    json_object = {}\n",
    "    print(f\"Processing (Trafilatura): {filename}\")\n",
    "    with open(os.path.join(BASE_URI, filename), 'r', encoding='utf-8') as file:\n",
    "        try:\n",
    "            html_content = file.read()\n",
    "            result = trafilatura.extract(html_content, no_fallback=True, include_links=False, include_comments=False,\n",
    "                                         include_tables=False, include_images=False, include_formatting=True)\n",
    "            metadata = trafilatura.extract_metadata(html_content)\n",
    "            json_object['title'] = metadata['title'] if metadata else None\n",
    "            json_object['main_text'] = clean_text(result) if result else None\n",
    "            json_object['filename'] = filename\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {str(e)}\")\n",
    "\n",
    "    return json_object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 5: Create a Function to Extract Text Using NewsPlease**\n",
    "\n",
    "The `extract_text_newsplease` function processes an HTML file to extract structured news information using NewsPlease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_newsplease(filename):\n",
    "    \"\"\"\n",
    "    Extracts text and metadata from an HTML file using NewsPlease.\n",
    "    \"\"\"\n",
    "    json_object = {}\n",
    "    print(f\"Processing (NewsPlease): {filename}\")\n",
    "    with open(os.path.join(BASE_URI, filename), 'r', encoding='utf-8') as file:\n",
    "        try:\n",
    "            news = NewsPlease.from_html(file.read())\n",
    "            json_object['title'] = news.title\n",
    "            json_object['description'] = news.description\n",
    "            json_object['main_text'] = news.maintext\n",
    "            json_object['language'] = news.language\n",
    "            json_object['filename'] = filename\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {str(e)}\")\n",
    "\n",
    "    return json_object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 6: Process Files Using Multiprocessing**\n",
    "\n",
    "We use Python's `multiprocessing` to process multiple HTML files in parallel for efficiency. This block processes all files in the `html` folder using both `Trafilatura` and `NewsPlease`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing (Trafilatura): 5541148.html\n",
      "Processing (Trafilatura): 5541142.html\n",
      "Error processing 5541148.html: 'Document' object is not subscriptable\n",
      "Processing (Trafilatura): 5541182.html\n",
      "Error processing 5541142.html: 'Document' object is not subscriptable\n",
      "Processing (Trafilatura): 5541176.html\n",
      "Error processing 5541182.html: 'Document' object is not subscriptable\n",
      "Processing (Trafilatura): 5541219.html\n",
      "Error processing 5541219.html: 'Document' object is not subscriptable\n",
      "Processing (Trafilatura): 5541224.html\n",
      "Error processing 5541224.html: 'Document' object is not subscriptable\n",
      "Processing (Trafilatura): 5541193.html\n",
      "Error processing 5541176.html: 'Document' object is not subscriptable\n",
      "Processing (Trafilatura): 5541165.html\n",
      "Error processing 5541193.html: 'Document' object is not subscriptable\n",
      "Processing (Trafilatura): 5541226.html\n",
      "Error processing 5541226.html: 'Document' object is not subscriptable\n",
      "Processing (Trafilatura): 5541160.html\n",
      "Error processing 5541160.html: 'Document' object is not subscriptable\n",
      "Processing (Trafilatura): 5541162.html\n",
      "Error processing 5541162.html: 'Document' object is not subscriptable\n",
      "Processing (Trafilatura): 5541232.html\n",
      "Error processing 5541232.html: 'Document' object is not subscriptable\n",
      "Processing (Trafilatura): 5541177.html\n",
      "Error processing 5541177.html: 'Document' object is not subscriptable\n",
      "Processing (Trafilatura): 5541151.html\n",
      "Error processing 5541151.html: 'Document' object is not subscriptable\n",
      "Processing (Trafilatura): 5541155.html\n",
      "Error processing 5541155.html: 'Document' object is not subscriptable\n",
      "Processing (Trafilatura): 5541197.html\n",
      "Error processing 5541165.html: 'Document' object is not subscriptable\n",
      "Processing (Trafilatura): 5541172.html\n",
      "Error processing 5541172.html: 'Document' object is not subscriptable\n",
      "Processing (Trafilatura): 5541181.html\n",
      "Error processing 5541181.html: 'Document' object is not subscriptable\n",
      "Processing (Trafilatura): 5541233.html\n",
      "Error processing 5541233.html: 'Document' object is not subscriptable\n",
      "Processing (Trafilatura): 5541225.html\n",
      "Error processing 5541225.html: 'Document' object is not subscriptable\n",
      "Processing (Trafilatura): 5541100.html\n",
      "Error processing 5541100.html: 'Document' object is not subscriptable\n",
      "Processing (Trafilatura): 5541216.html\n",
      "Error processing 5541216.html: 'Document' object is not subscriptable\n",
      "Processing (Trafilatura): 5541188.html\n",
      "Error processing 5541188.html: 'Document' object is not subscriptable\n",
      "Processing (Trafilatura): 5541209.html\n",
      "Error processing 5541209.html: 'Document' object is not subscriptable\n",
      "Processing (Trafilatura): 5541234.html\n",
      "Error processing 5541234.html: 'Document' object is not subscriptable\n",
      "Processing (Trafilatura): 5541186.html\n",
      "Error processing 5541186.html: 'Document' object is not subscriptable\n",
      "Processing (Trafilatura): 5541169.html\n",
      "Error processing 5541197.html: 'Document' object is not subscriptable\n",
      "Processing (Trafilatura): 5541180.html\n",
      "Error processing 5541169.html: 'Document' object is not subscriptable\n",
      "Processing (Trafilatura): 5541183.html\n",
      "Error processing 5541183.html: 'Document' object is not subscriptable\n",
      "Processing (Trafilatura): 5541152.html\n",
      "Error processing 5541152.html: 'Document' object is not subscriptable\n",
      "Processing (Trafilatura): 5541205.html\n",
      "Error processing 5541180.html: 'Document' object is not subscriptable\n",
      "Processing (Trafilatura): 5541163.html\n",
      "Error processing 5541163.html: 'Document' object is not subscriptable\n",
      "Processing (Trafilatura): 5541167.html\n",
      "Error processing 5541167.html: 'Document' object is not subscriptable\n",
      "Processing (Trafilatura): 5541191.html\n",
      "Error processing 5541191.html: 'Document' object is not subscriptable\n",
      "Processing (Trafilatura): 5541145.html\n",
      "Error processing 5541145.html: 'Document' object is not subscriptable\n",
      "Processing (Trafilatura): 5541229.html\n",
      "Error processing 5541229.html: 'Document' object is not subscriptable\n",
      "Error processing 5541205.html: 'Document' object is not subscriptable\n",
      "Processing (Trafilatura): 5541203.html\n",
      "Error processing 5541203.html: 'Document' object is not subscriptable\n",
      "Processing (Trafilatura): 5541220.html\n",
      "Error processing 5541220.html: 'Document' object is not subscriptable\n",
      "Processing (Trafilatura): 726.html\n",
      "Error processing 726.html: 'Document' object is not subscriptable\n",
      "Processing (NewsPlease): 5541148.htmlProcessing (NewsPlease): 5541142.html\n",
      "\n",
      "JSON data written to 'html_json_trafilatura.json'\n",
      "Starting NewsPlease extraction...\n",
      "Processing (NewsPlease): 5541182.html\n",
      "Processing (NewsPlease): 5541176.html\n",
      "Processing (NewsPlease): 5541165.html\n",
      "Processing (NewsPlease): 5541172.html\n",
      "Processing (NewsPlease): 5541181.html\n",
      "Processing (NewsPlease): 5541226.html\n",
      "Processing (NewsPlease): 5541219.html\n",
      "Processing (NewsPlease): 5541160.html\n",
      "Processing (NewsPlease): 5541162.html\n",
      "Processing (NewsPlease): 5541224.html\n",
      "Processing (NewsPlease): 5541193.html\n",
      "Processing (NewsPlease): 5541151.html\n",
      "Processing (NewsPlease): 5541232.html\n",
      "Processing (NewsPlease): 5541177.html\n",
      "Processing (NewsPlease): 5541233.html\n",
      "Processing (NewsPlease): 5541225.html\n",
      "Processing (NewsPlease): 5541155.html\n",
      "Processing (NewsPlease): 5541197.html\n",
      "Processing (NewsPlease): 5541180.html\n",
      "Processing (NewsPlease): 5541100.html\n",
      "Processing (NewsPlease): 5541216.html\n",
      "Processing (NewsPlease): 5541188.html\n",
      "Processing (NewsPlease): 5541209.html\n",
      "Processing (NewsPlease): 5541234.html\n",
      "Processing (NewsPlease): 5541163.html\n",
      "Processing (NewsPlease): 5541186.html\n",
      "Processing (NewsPlease): 5541169.html\n",
      "Processing (NewsPlease): 5541183.html\n",
      "Processing (NewsPlease): 5541152.html\n",
      "Processing (NewsPlease): 5541167.html\n",
      "Processing (NewsPlease): 5541205.html\n",
      "Processing (NewsPlease): 5541191.html\n",
      "Processing (NewsPlease): 5541145.html\n",
      "Processing (NewsPlease): 5541229.html\n",
      "Processing (NewsPlease): 5541203.html\n",
      "Processing (NewsPlease): 5541220.html\n",
      "Processing (NewsPlease): 726.html\n",
      "NewsPlease extraction completed. Output saved to 'html_json_newsplease.json'.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Use a multiprocessing pool to process files in parallel\n",
    "    pool = multiprocessing.Pool(os.cpu_count()) \n",
    "    res = pool.map(extract_text_trafilatura, os.listdir(BASE_URI))\n",
    "    with open('html_json_trafilatura.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(res, f, ensure_ascii=False, indent=4)\n",
    "    print(\"JSON data written to 'html_json_trafilatura.json'\")\n",
    "\n",
    "    # Extract text using NewsPlease\n",
    "    print(\"Starting NewsPlease extraction...\")\n",
    "    newsplease_results = pool.map(extract_text_newsplease, os.listdir(BASE_URI))\n",
    "    with open('html_json_newsplease.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(newsplease_results, f, ensure_ascii=False, indent=4)\n",
    "    print(\"NewsPlease extraction completed. Output saved to 'html_json_newsplease.json'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Final Notes**\n",
    "\n",
    "This notebook demonstrates how to extract clean and structured text from HTML files using two methods. The results are saved as JSON files:\n",
    "\n",
    "1. `html_json_trafilatura.json`: Output from Trafilatura.\n",
    "2. `html_json_newsplease.json`: Output from NewsPlease.\n",
    "\n",
    "You can analyze these JSON files further for your research or application needs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
